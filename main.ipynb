{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonfiles.data_class import *\n",
    "from pythonfiles.generator import GenModel\n",
    "from pythonfiles.discriminator import DisModel\n",
    "from pythonfiles.model_utility import *\n",
    "\n",
    "\n",
    "from torchsummary import summary\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    'z_shape': 128,\n",
    "    'gen_final_layer_size': 3,\n",
    "    'image_input_shape': 64,\n",
    "    'batch_size': 256,\n",
    "    'epochs': 5\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using the  Device -  cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using the  Device - \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gen_model = GenModel(hparams)\n",
    "dis_model = DisModel(hparams)\n",
    "\n",
    "dis_model = dis_model.apply(init_weights)\n",
    "gen_model = gen_model.apply(init_weights)\n",
    "\n",
    "dis_model = dis_model.to(device)\n",
    "gen_model = gen_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gen_optimizer = torch.optim.Adam(gen_model.parameters(),lr=0.0002,betas=(0.5, 0.999))\n",
    "dis_optimizer = torch.optim.Adam(dis_model.parameters(),lr=0.0002,betas=(0.5, 0.999))\n",
    "loss_function = torch.nn.BCELoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " logdir = \"logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    " writer = SummaryWriter(logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from torchsummary import summary\n",
    "#dis_model =  DisModel(hparams)\n",
    "#dis_model.cuda()\n",
    "#summary(dis_model,(3,64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_dataloader = data_setup(batch_size=hparams['batch_size'],foldername=\"data/realimagessmall\")\n",
    "real_label = torch.ones(hparams['batch_size'], 1,device=device)\n",
    "fake_label = torch.zeros(hparams['batch_size'], 1,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▏         | 1/50 [00:35<28:59, 35.49s/it]\u001b[A\n",
      "  4%|▍         | 2/50 [00:36<11:58, 14.97s/it]\u001b[A\n",
      "  6%|▌         | 3/50 [00:36<06:35,  8.41s/it]\u001b[A\n",
      "  8%|▊         | 4/50 [00:37<04:05,  5.33s/it]\u001b[A\n",
      " 10%|█         | 5/50 [00:37<02:43,  3.63s/it]\u001b[A\n",
      " 12%|█▏        | 6/50 [00:38<01:54,  2.60s/it]\u001b[A\n",
      " 14%|█▍        | 7/50 [01:09<08:30, 11.88s/it]\u001b[A\n",
      " 16%|█▌        | 8/50 [01:10<05:48,  8.29s/it]\u001b[A\n",
      " 18%|█▊        | 9/50 [01:10<04:01,  5.89s/it]\u001b[A\n",
      " 20%|██        | 10/50 [01:11<02:50,  4.26s/it]\u001b[A\n",
      " 22%|██▏       | 11/50 [01:11<02:02,  3.14s/it]\u001b[A\n",
      " 24%|██▍       | 12/50 [01:12<01:30,  2.37s/it]\u001b[A\n",
      " 26%|██▌       | 13/50 [01:41<06:27, 10.47s/it]\u001b[A\n",
      " 28%|██▊       | 14/50 [01:42<04:36,  7.67s/it]\u001b[A\n",
      " 30%|███       | 15/50 [01:43<03:13,  5.54s/it]\u001b[A\n",
      " 32%|███▏      | 16/50 [01:44<02:17,  4.06s/it]\u001b[A\n",
      " 34%|███▍      | 17/50 [01:44<01:39,  3.02s/it]\u001b[A\n",
      " 36%|███▌      | 18/50 [01:45<01:13,  2.29s/it]\u001b[A\n",
      " 38%|███▊      | 19/50 [02:21<06:26, 12.47s/it]\u001b[A\n",
      " 40%|████      | 20/50 [02:22<04:33,  9.13s/it]\u001b[A\n",
      " 42%|████▏     | 21/50 [02:23<03:10,  6.57s/it]\u001b[A\n",
      " 44%|████▍     | 22/50 [02:24<02:14,  4.79s/it]\u001b[A\n",
      " 46%|████▌     | 23/50 [02:24<01:35,  3.54s/it]\u001b[A\n",
      " 48%|████▊     | 24/50 [02:25<01:09,  2.66s/it]\u001b[A\n",
      " 50%|█████     | 25/50 [02:53<04:18, 10.35s/it]\u001b[A\n",
      " 52%|█████▏    | 26/50 [02:54<03:03,  7.65s/it]\u001b[A\n",
      " 54%|█████▍    | 27/50 [02:55<02:07,  5.54s/it]\u001b[A\n",
      " 56%|█████▌    | 28/50 [02:56<01:29,  4.06s/it]\u001b[A\n",
      " 58%|█████▊    | 29/50 [02:56<01:03,  3.02s/it]\u001b[A\n",
      " 60%|██████    | 30/50 [02:57<00:45,  2.30s/it]\u001b[A\n",
      " 62%|██████▏   | 31/50 [03:24<03:07,  9.89s/it]\u001b[A\n",
      " 64%|██████▍   | 32/50 [03:26<02:11,  7.31s/it]\u001b[A\n",
      " 66%|██████▌   | 33/50 [03:26<01:30,  5.30s/it]\u001b[A\n",
      " 68%|██████▊   | 34/50 [03:27<01:02,  3.90s/it]\u001b[A\n",
      " 70%|███████   | 35/50 [03:28<00:43,  2.92s/it]\u001b[A\n",
      " 72%|███████▏  | 36/50 [03:28<00:31,  2.23s/it]\u001b[A\n",
      " 74%|███████▍  | 37/50 [04:01<02:29, 11.52s/it]\u001b[A\n",
      " 76%|███████▌  | 38/50 [04:02<01:40,  8.38s/it]\u001b[A\n",
      " 78%|███████▊  | 39/50 [04:03<01:06,  6.05s/it]\u001b[A\n",
      " 80%|████████  | 40/50 [04:04<00:44,  4.42s/it]\u001b[A\n",
      " 82%|████████▏ | 41/50 [04:04<00:29,  3.27s/it]\u001b[A\n",
      " 84%|████████▍ | 42/50 [04:05<00:19,  2.47s/it]\u001b[A\n",
      " 86%|████████▌ | 43/50 [04:34<01:12, 10.40s/it]\u001b[A\n",
      " 88%|████████▊ | 44/50 [04:35<00:45,  7.52s/it]\u001b[A\n",
      " 90%|█████████ | 45/50 [04:35<00:27,  5.45s/it]\u001b[A\n",
      " 92%|█████████▏| 46/50 [04:36<00:15,  4.00s/it]\u001b[A\n",
      " 94%|█████████▍| 47/50 [04:36<00:08,  2.99s/it]\u001b[A\n",
      " 96%|█████████▌| 48/50 [04:37<00:04,  2.28s/it]\u001b[A\n",
      " 98%|█████████▊| 49/50 [04:47<00:04,  4.45s/it]\u001b[A\n",
      "100%|██████████| 50/50 [04:47<00:00,  5.76s/it]\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "  0%|          | 0/5 [04:47<?, ?it/s]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-390b6b2e2127>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mimg_out\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfake_image\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0mimg_out\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_out\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "dis_fn_real_list = []\n",
    "dis_fn_fake_list = []\n",
    "\n",
    "dis_loss_list = []\n",
    "gen_loss_list = []\n",
    "cntr = 0\n",
    "for epoch in tqdm(range(hparams['epochs'])):\n",
    "    for data in tqdm(real_dataloader):\n",
    "\n",
    "        #dis_model.zero_grad()\n",
    "        dis_optimizer.zero_grad()\n",
    "\n",
    "        # Discriminator update for real data\n",
    "        data = data[0]\n",
    "        data = data.to(device)\n",
    "\n",
    "        real_outputs = dis_model(data)\n",
    "        #dis_fn_real_list.append(torch.mean(real_outputs.detach().cpu()))\n",
    "        #writer.add_scalar('Discriminator Function Real',\n",
    "        #                  torch.mean(real_outputs.detach().cpu()), cntr)\n",
    "        real_loss = loss_function(real_outputs, real_label)\n",
    "        real_loss.backward()\n",
    "        running_real_loss = real_loss.item()\n",
    "\n",
    "        # Discriminator update for fake data\n",
    "\n",
    "        fake_noise = torch.randn(\n",
    "            hparams['batch_size'], hparams['z_shape'], 1, 1, device=device)\n",
    "        fake_image = gen_model(fake_noise)\n",
    "        fake_outputs = dis_model(fake_image.detach())\n",
    "        #dis_fn_fake_list.append((torch.mean(fake_outputs)).numpy())\n",
    "        #writer.add_scalar('Discriminator Function Fake',\n",
    "          #                torch.mean(fake_outputs.detach().cpu()), cntr)\n",
    "\n",
    "        fake_loss = loss_function(fake_outputs, fake_label)\n",
    "        fake_loss.backward()\n",
    "        running_fake_loss = fake_loss.item()\n",
    "        dis_loss = running_fake_loss+running_real_loss\n",
    "\n",
    "        dis_loss_list.append(dis_loss)\n",
    "        writer.add_scalar('Discriminator Loss',\n",
    "                         running_fake_loss+running_real_loss, cntr)\n",
    "\n",
    "        dis_optimizer.step()\n",
    "\n",
    "        # Generator update\n",
    "\n",
    "        # fake_noise = torch.randn(\n",
    "        #   hparams['batch_size'], hparams['z_shape'], 1, 1,device=device)\n",
    "        #fake_image = gen_model(fake_noise)\n",
    "        gen_optimizer.zero_grad()\n",
    "        #gen_model.zero_grad()\n",
    "        fake_outputs = dis_model(fake_image)\n",
    "\n",
    "        gen_loss = loss_function(fake_outputs, real_label)\n",
    "        running_gen_loss = gen_loss.item()\n",
    "        gen_loss_list.append(running_gen_loss)\n",
    "        writer.add_scalar('Generator Loss', running_gen_loss, cntr)\n",
    "        gen_loss.backward()\n",
    "        gen_optimizer.step()\n",
    "\n",
    "        cntr += 1\n",
    "\n",
    "       \n",
    "    \n",
    "    \n",
    "    torch.save(dis_model.state_dict(), \"models/dis\"+str(epoch))\n",
    "    torch.save(gen_model.state_dict(), \"models/gen\"+str(epoch))\n",
    "\n",
    "    for idx in tqdm(range(int(hparams['batch_size']/20))):\n",
    "        img_out=fake_image[idx].detach().cpu().numpy()\n",
    "        img_out=np.transpose(img_out,(1,2,0))\n",
    "\n",
    "        img_out_rescaled=(img_out+1)*255/2\n",
    "        img_out_rescaled=img_out_rescaled.astype(np.uint8)\n",
    "        \n",
    "        plt.imsave(\"figures/sample_epoch\"+str(epoch)+\"_\"+str(idx)+\".png\",img_out_rescaled)\n",
    "     \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 53.57it/s]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit ('pyt': conda)",
   "metadata": {
    "interpreter": {
     "hash": "db440c4a8e798f4d47c24a1927ce96fdafb76acfbff3d1f458d7c095892c2a7b"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}